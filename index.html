<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Arjun Somayazulu</title>

    <meta name="author" content="Arjun Somayazulu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,700;1,300;1,700&display=swap" rel="stylesheet">
  </head>

  <body>
    <table style="width:100%;max-width:1200px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:top">
                <p class="name" style="text-align: center;">
                  Arjun Somayazulu
                </p>
                <p>I'm a third-year Ph.D. student at UT Austin advised by Prof. <a href="https://www.cs.utexas.edu/users/grauman/">Kristen Grauman</a>. I'm
                  broadly interested in computer vision and multi-modal perception, and my current line of research is in multi-modal video understanding using vision, language, audio, and 3D human pose.
                </p>
                <p>
                  Previously, I received B.S degrees in Computer Science and Biomedical Engineering from Johns Hopkins, where I was advised by Prof. <a href="https://www.bu.edu/eng/profile/archana-venkataraman-ph-d/">Archana Venkataraman</a>.
                </p>
                <p style="text-align:center">
                  <a href="files/CV_1_2024.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="mailto:ars7452@my.utexas.edu">Email</a> &nbsp;/&nbsp;
                  <a href="https://github.com/arjunrs1/">GitHub</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/profile_photo_trimmed.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 0%;" alt="profile photo" src="images/profile_photo_trimmed.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:5px;width:100%;vertical-align:top">
                  <h2>News</h2>
                </td>
              </tr>
              <tr>
                <td style="padding:5px 20px;width:100%;vertical-align:top">
                  <strong>May 2024</strong> Our IROS 2024 Oral, <a href="https://vision.cs.utexas.edu/projects/active_rir/">ActiveRIR</a>, is featured on <a href="https://techxplore.com/news/2024-05-approach-efficiently-acoustics-environment.html">TechXplore</a>.
                </td>
              </tr>
              <tr>
                <td style="padding:5px 20px;width:100%;vertical-align:top">
                  <strong>May 2024</strong> Joining <a href="https://ai.meta.com/research/">Meta FAIR</a> in New York for the summer, working on video temporal grounding.
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:5px;width:100%;vertical-align:top">
                <h2>Papers</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr class="paper-entry" onmouseout="view_inv_stop()" onmouseover="view_inv_start()">
              <td style="padding:5px;width:25%;vertical-align:top">
                <div class="one">
                  <div class="two" id='view_inv_image'></div>
                  <img src='images/view_inv_figure.pdf' width="260" alt="view_inv figure">
                </div>
                <script>
                  function view_inv_start() {
                    document.getElementById('view_inv_image').style.opacity = "1";
                  }

                  function view_inv_stop() {
                    document.getElementById('view_inv_image').style.opacity = "0";
                  }
                  view_inv_stop()
                </script>
              </td>
              <td style="padding:5px;width:75%;vertical-align:top">
                <a href="https://vision.cs.utexas.edu/projects/view_inv_learning/">
                  <span class="papertitle">Learning Activity View-invariance Under Extreme Viewpoint Changes via Curriculum Knowledge Distillation</span>
                </a>
                <br>
                <strong>Arjun Somayazulu</strong>,
                Sagnik Majumder,
                Changan Chen,
                Kristen Grauman,
                <br>
                <em>arXiv 2025 (Under submission)</em>
                <br>
                <a href="https://arxiv.org/abs/2504.05451">arXiv</a>
              </td>
            </tr> 

            <tr class="paper-entry" onmouseout="active_rir_stop()" onmouseover="active_rir_start()">
              <td style="padding:5px;width:25%;vertical-align:top">
                <div class="one">
                  <div class="two" id='active_rir_image'></div>
                  <img src='images/active_rir_figure.png' width="260" alt="active_rir figure">
                </div>
                <script>
                  function active_rir_start() {
                    document.getElementById('active_rir_image').style.opacity = "1";
                  }

                  function active_rir_stop() {
                    document.getElementById('active_rir_image').style.opacity = "0";
                  }
                  active_rir_stop()
                </script>
              </td>
              <td style="padding:5px;width:75%;vertical-align:top">
                <a href="https://vision.cs.utexas.edu/projects/active_rir/">
                  <span class="papertitle">ActiveRIR: Active Audio-Visual Exploration for
                    Acoustic Environment Modeling</span>
                </a>
                <br>
                <strong>Arjun Somayazulu</strong>,
                Sagnik Majumder,
                Changan Chen,
                Kristen Grauman,
                <br>
                <em>IROS 2024</em>
                <span class="red">(Oral)</span>
                <br>
                <a href="https://vision.cs.utexas.edu/projects/active_rir/">project</a>
                |
                <a href="https://arxiv.org/abs/2404.16216">paper</a>
                |
                <a href="https://techxplore.com/news/2024-05-approach-efficiently-acoustics-environment.html">press</a>
              </td>
            </tr>      
            
            <tr class="paper-entry" onmouseout="ego_exo_stop()" onmouseover="ego_exo_start()">
              <td style="padding:5px;width:25%;vertical-align:top">
                <div class="one">
                  <div class="two" id='ego_exo_image'></div>
                  <img src='images/ego_exo_figure.png' width="260" alt="ego_exo figure">
                </div>
                <script>
                  function ss_vam_start() {
                    document.getElementById('ego_exo_image').style.opacity = "1";
                  }

                  function ss_vam_stop() {
                    document.getElementById('ego_exo_image').style.opacity = "0";
                  }
                  ss_vam_stop()
                </script>
              </td>
              <td style="padding:5px;width:75%;vertical-align:top">
                <a href="https://ego-exo4d-data.org/">
                  <span class="papertitle">Ego-Exo4D: Understanding Skilled Human Activity from First- and Third-Person Perspectives</span>
                </a>
                <br>
                Kristen Grauman, 
                Andrew Westbury,
Lorenzo Torresani,
Kris M. Kitani,
Jitendra Malik, ...
<strong>Arjun Somayazulu</strong>, ...
Pablo Arbelaez,
Gedas Bertasius,
Dima Damen,
Jakob Engel,
Giovanni Maria Farinella,
Antonino Furnari,
Bernard Ghanem,
Judy Hoffman,
C.V. Jawahar,
Richard Newcombe,
Hyun Soo Park,
James Matthew Rehg,
Yoichi Sato,
Manolis Savva,
Jianbo Shi,
Mike Zheng Shou,
Michael Wray.
                <br>
                 <em>CVPR 2024</em>
                 <span class="red">(Oral)</span>
                 <br>
                 <a href="https://ego-exo4d-data.org/">website</a>
                 |
                 <a href="https://arxiv.org/abs/2311.18259">paper</a>
                 |
                 <a href="https://www.youtube.com/watch?v=GdooXEBAnI8">video</a>
              </td>
            </tr>
            
            <tr class="paper-entry" onmouseout="ss_vam_stop()" onmouseover="ss_vam_start()">
              <td style="padding:5px;width:25%;vertical-align:top">
                <div class="one">
                  <div class="two" id='ss_vam_image'></div>
                  <img src='images/ss_vam_figure.png' width="260" alt="ss_vam figure">
                </div>
                <script>
                  function ss_vam_start() {
                    document.getElementById('ss_vam_image').style.opacity = "1";
                  }

                  function ss_vam_stop() {
                    document.getElementById('ss_vam_image').style.opacity = "0";
                  }
                  ss_vam_stop()
                </script>
              </td>
              <td style="padding:5px;width:75%;vertical-align:top">
                <a href="https://vision.cs.utexas.edu/projects/ss_vam/">
                  <span class="papertitle">Self-Supervised Visual Acoustic Matching</span>
                </a>
                <br>
                <strong>Arjun Somayazulu</strong>,
                Changan Chen,
                Kristen Grauman,
                <br>
                <em>NeurIPS 2023</em>
                <br>
                <a href="https://vision.cs.utexas.edu/projects/ss_vam/">project</a>
                |
                <a href="https://arxiv.org/abs/2307.15064">paper</a>
              </td>
            </tr>

            <tr class="paper-entry" onmouseout="comp_aug_stop()" onmouseover="comp_aug_start()">
              <td style="padding:5px;width:25%;vertical-align:top">
                <div class="one">
                  <div class="two" id='comp_aug_image'></div>
                  <img src='images/comp_aug.png' width="260" alt="comp_aug image">
                </div>
                <script>
                  function comp_aug_start() {
                    document.getElementById('comp_aug_image').style.opacity = "1";
                  }

                  function comp_aug_stop() {
                    document.getElementById('comp_aug_image').style.opacity = "0";
                  }
                  ss_vam_stop()
                </script>
              </td>
              <td style="padding:5px;width:75%;vertical-align:top">
                <a href="https://arxiv.org/abs/2211.05047">
                  <span class="papertitle">A Comparative Study of Data Augmentation Techniques for Deep Learning Based Emotion Recognition</span>
                </a>
                <br>
                Ravi Shankar,
                Abdouh Harouna,
                <strong>Arjun Somayazulu</strong>,
                Archana Venkataraman,
                <br>
                <em>ArXiv 2023</em>
                <br>
                <a href="https://arxiv.org/abs/2211.05047">paper</a>
              </td>
            </tr>

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:5px;width:100%;vertical-align:top">
                <h2>Teaching/Service</h2>
              </td>
            </tr>
            <tr>
              <td style="padding:5px 20px;width:100%;vertical-align:top">
                <strong>Spring 2021 -</strong> Course Assistant, EN.601.226 Data Structures 
              </td>
            </tr>
            <tr>
              <td style="padding:5px 20px;width:100%;vertical-align:top">
                <strong>Fall 2021 -</strong> Course Assistant, EN.601.475/675 Machine Learning
              </td>
            </tr>
            <tr>
              <td style="padding:5px 20px;width:100%;vertical-align:top">
                Reviewer for <strong>CVPR 2024, IROS 2024, CVPR 2025, NeurIPS 2025, CVIU 2025</strong>
              </td>
            </tr>
          </tbody>
        </table>
        </td>
      </tr>
    </table>
  </body>
</html>